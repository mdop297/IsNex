{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ed2c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment from /home/nhatminh/Desktop/IsNex/envs/.env.dev\n",
      "\u001b[2m2026-01-07T17:10:58.496420Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLogger initialized            \u001b[0m [\u001b[0m\u001b[1m\u001b[34msrc.core.utils.logger\u001b[0m]\u001b[0m \u001b[36menvironment\u001b[0m=\u001b[35mdevelopment\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mlogger.py\u001b[0m \u001b[36mfunc_name\u001b[0m=\u001b[35m<module>\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m280\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mlogger\u001b[0m \u001b[36mpathname\u001b[0m=\u001b[35m/home/nhatminh/Desktop/IsNex/apps/documents/src/core/utils/logger.py\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import (\n",
    "    HumanMessage,\n",
    ")\n",
    "import asyncio\n",
    "from src.core.utils.logger import logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e692e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain.agents.middleware import before_model, after_model, AgentState\n",
    "from langchain.messages import AIMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model(can_jump_to=[\"end\"])\n",
    "def check_message_limit(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    if len(state[\"messages\"]) >= 50:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(\"Conversation limit reached.\")],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    return None\n",
    "\n",
    "@after_model\n",
    "def log_response(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(\"======================== STATE ========================\")\n",
    "    pprint(state)\n",
    "    print(\"======================== STATE ========================\")\n",
    "    print(\"======================== RUNTIME ========================\")\n",
    "    pprint(runtime)\n",
    "    print(\"======================== RUNTIME ========================\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fdada28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from src.agent.model_catalog import AgentContext, ModelCatalog, SupportedModels\n",
    "from src.agent.model_catalog import model_selector\n",
    "from src.agent.tools import tools\n",
    "\n",
    "\n",
    "model = ModelCatalog.get_model(model_name=SupportedModels.DEEPSEEK_V3_1_NEX_N1_FREE)\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate. Only use tools when you realy need it.\",\n",
    "    middleware=[model_selector],  # type: ignore\n",
    "    context_schema=AgentContext,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a981db",
   "metadata": {},
   "outputs": [],
   "source": [
    "message =HumanMessage(content=\"hello, which large language model are you, who created you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babca8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "# import asyncio if needed elsewhere\n",
    "\n",
    "from src.agent.model_catalog import SupportedModels\n",
    "\n",
    "async def generate(\n",
    "    message: HumanMessage,\n",
    "    model_name: str\n",
    "):\n",
    "    try:\n",
    "        print(\"================ 2 ================\")\n",
    "        \n",
    "        # mlflow_langchain.autolog()\n",
    "        config: RunnableConfig = {\n",
    "            \"configurable\": {\"model_name\": model_name}\n",
    "        }\n",
    "        \n",
    "        for chunk in agent.stream(\n",
    "            {\"messages\": [message]},\n",
    "            stream_mode=\"messages\",\n",
    "            context=AgentContext(model_name=model_name),\n",
    "        ):\n",
    "            \n",
    "            yield chunk\n",
    "\n",
    "    except asyncio.CancelledError:\n",
    "        logger.warning(\"Stream cancelled by client\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during streaming: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4eb9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ 2 ================\n",
      "================ 3 ================\n",
      "======================== REQUEST ========================\n",
      "ModelRequest(model=ChatOpenAI(profile={}, client=<openai.resources.chat.completions.completions.Completions object at 0x7b8a94af1010>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7b8a94af1a90>, root_client=<openai.OpenAI object at 0x7b8a94fd6120>, root_async_client=<openai.AsyncOpenAI object at 0x7b8a94af17f0>, model_name='nex-agi/deepseek-v3.1-nex-n1:free', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://openrouter.ai/api/v1'),\n",
      "             messages=[HumanMessage(content='hello, which large language model are you, who created you?', additional_kwargs={}, response_metadata={}, id='4b491b8f-9013-4b51-9a62-9e42592207e4')],\n",
      "             system_message=SystemMessage(content='You are a helpful assistant. Be concise and accurate. Only use tools when you realy need it.', additional_kwargs={}, response_metadata={}),\n",
      "             tool_choice=None,\n",
      "             tools=[StructuredTool(name='get_weather', description='Get the weather for a location', args_schema=<class 'langchain_core.utils.pydantic.get_weather'>, func=<function get_weather at 0x7b8a95ea5620>),\n",
      "                    StructuredTool(name='calculate', description='Calculate a mathematical expression', args_schema=<class 'langchain_core.utils.pydantic.calculate'>, func=<function calculate at 0x7b8a95e64fe0>),\n",
      "                    StructuredTool(name='search_web', description='Search the web for information', args_schema=<class 'langchain_core.utils.pydantic.search_web'>, func=<function search_web at 0x7b8a95e65120>)],\n",
      "             response_format=None,\n",
      "             state={'messages': [HumanMessage(content='hello, which large language model are you, who created you?', additional_kwargs={}, response_metadata={}, id='4b491b8f-9013-4b51-9a62-9e42592207e4')]},\n",
      "             runtime=Runtime(context=AgentContext(model_name='grok-4.1-fast',\n",
      "                                                  user_girlfriend='Jane Doe'),\n",
      "                             store=None,\n",
      "                             stream_writer=<function Pregel.stream.<locals>.stream_writer at 0x7b8a969bfba0>,\n",
      "                             previous=None),\n",
      "             model_settings={})\n",
      "======================== REQUEST ========================\n",
      "======================== CONTEXT ========================\n",
      "AgentContext(model_name='grok-4.1-fast', user_girlfriend='Jane Doe')\n",
      "======================== CONTEXT ========================\n",
      "================ 4 ================\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-99dca532-840b-4d1a-ad9c-75618f559b30', 'json_data': {'messages': [{'content': 'You are a helpful assistant. Be concise and accurate. Only use tools when you realy need it.', 'role': 'system'}, {'content': 'hello, which large language model are you, who created you?', 'role': 'user'}], 'model': 'x-ai/grok-4.1-fast', 'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'get_weather', 'description': 'Get the weather for a location', 'parameters': {'properties': {'location': {'type': 'string'}}, 'required': ['location'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'calculate', 'description': 'Calculate a mathematical expression', 'parameters': {'properties': {'expression': {'type': 'string'}}, 'required': ['expression'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'search_web', 'description': 'Search the web for information', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}}\n",
      "Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=None socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b8a8bf5c690>\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x7b8a95e65270> server_hostname='openrouter.ai' timeout=None\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b8a9461a520>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Jan 2026 17:12:16 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9ba514378aa3dd4a-SIN'), (b'Access-Control-Allow-Origin', b'*'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Accept-Encoding'), (b'Permissions-Policy', b'payment=(self \"https://checkout.stripe.com\" \"https://connect-js.stripe.com\" \"https://js.stripe.com\" \"https://*.js.stripe.com\" \"https://hooks.stripe.com\")'), (b'Referrer-Policy', b'no-referrer, strict-origin-when-cross-origin'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare')])\n",
      "HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 07 Jan 2026 17:12:16 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9ba514378aa3dd4a-SIN', 'access-control-allow-origin': '*', 'cache-control': 'no-cache', 'vary': 'Accept-Encoding', 'permissions-policy': 'payment=(self \"https://checkout.stripe.com\" \"https://connect-js.stripe.com\" \"https://js.stripe.com\" \"https://*.js.stripe.com\" \"https://hooks.stripe.com\")', 'referrer-policy': 'no-referrer, strict-origin-when-cross-origin', 'x-content-type-options': 'nosniff', 'server': 'cloudflare'})\n",
      "request_id: None\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=\"I'm\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' Gro', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='k', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' large', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' model', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' built', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content=' x', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='AI', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'x-ai/grok-4.1-fast', 'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a', usage_metadata={'input_tokens': 454, 'output_tokens': 228, 'total_tokens': 682, 'input_token_details': {'audio': 0, 'cache_read': 150}, 'output_token_details': {'reasoning': 215}}), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "receive_response_body.failed exception=GeneratorExit()\n",
      "================ 1 ================\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--019b9971-de1b-7f83-8f43-da1f416a4b8a', chunk_position='last'), {'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'checkpoint_ns': 'model:6a5cd380-6d1a-702a-c91f-8cc08e766bca', 'ls_provider': 'openai', 'ls_model_name': 'x-ai/grok-4.1-fast', 'ls_model_type': 'chat', 'ls_temperature': None})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "async for chunk in generate(message, model_name=SupportedModels.GROK_4_1_FAST):\n",
    "    print(\"================ 1 ================\")\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa87fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
