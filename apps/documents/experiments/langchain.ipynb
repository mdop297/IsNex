{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301a8433",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41ab8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/19 19:54:41 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/19 19:54:41 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/19 19:54:41 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/19 19:54:41 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/19 19:54:41 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/19 19:54:41 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Optional: Set an experiment to organize your traces\n",
    "mlflow.set_experiment(\"IsNex Tracing\")\n",
    "\n",
    "# Enable tracing\n",
    "mlflow.langchain.autolog()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain.tools import tool\n",
    "from src.core.utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather for a location\"\"\"\n",
    "    # Fake weather data\n",
    "    return f\"The weather in {location} is sunny and 25°C\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate a mathematical expression\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for information\"\"\"\n",
    "    return f\"Search results for '{query}': Found 10 results about {query}\"\n",
    "\n",
    "\n",
    "tools = [get_weather, calculate, search_web]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6dc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_tool_call\n",
    "\n",
    "\n",
    "@wrap_tool_call\n",
    "def handle_tool_errors(request, handler):\n",
    "    \"\"\"Handle tool execution errors with custom messages.\"\"\"\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        # Return a custom error message to the model\n",
    "        return ToolMessage(\n",
    "            content=f\"Tool error: Please check your input and try again. ({str(e)})\",\n",
    "            tool_call_id=request.tool_call[\"id\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b53702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    max_completion_tokens=2048,\n",
    "    timeout=30,\n",
    ")\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    middleware=[handle_tool_errors],\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab15917",
   "metadata": {},
   "source": [
    "\n",
    "# Response output\n",
    "\n",
    "- AIMessage\n",
    "- AIMessageChunk (stream)\n",
    "  - Source\n",
    "  - Suggestion\n",
    "- ToolMessage\n",
    "\n",
    "- UserMessage\n",
    "\n",
    "## Output schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4268b64",
   "metadata": {},
   "source": [
    "# Experiments with models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30364b7",
   "metadata": {},
   "source": [
    "## get text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13e4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal text content, no streaming\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "result = model_with_tools.invoke(\"What is the weather in New York?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e5f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_kwargs': {'refusal': None},\n",
      " 'content': '',\n",
      " 'id': 'lc_run--019b36ad-8e71-70b0-946a-a3720d78a83e-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'tool_calls',\n",
      "                       'id': 'chatcmpl-CoUIaKSulPN8xOm5bhYTfxSAqOOB8',\n",
      "                       'logprobs': None,\n",
      "                       'model_name': 'gpt-5-nano-2025-08-07',\n",
      "                       'model_provider': 'openai',\n",
      "                       'service_tier': 'default',\n",
      "                       'system_fingerprint': None,\n",
      "                       'token_usage': {'completion_tokens': 88,\n",
      "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                                                     'audio_tokens': 0,\n",
      "                                                                     'reasoning_tokens': 64,\n",
      "                                                                     'rejected_prediction_tokens': 0},\n",
      "                                       'prompt_tokens': 171,\n",
      "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                                                 'cached_tokens': 0},\n",
      "                                       'total_tokens': 259}},\n",
      " 'tool_calls': [{'args': {'location': 'New York'},\n",
      "                 'id': 'call_T4VNsMnYYLrG1Ml44yKUin6E',\n",
      "                 'name': 'get_weather',\n",
      "                 'type': 'tool_call'}],\n",
      " 'type': 'ai',\n",
      " 'usage_metadata': {'input_token_details': {'audio': 0, 'cache_read': 0},\n",
      "                    'input_tokens': 171,\n",
      "                    'output_token_details': {'audio': 0, 'reasoning': 64},\n",
      "                    'output_tokens': 88,\n",
      "                    'total_tokens': 259}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# from langchain_core.messages import message_to_dict\n",
    "# message = message_to_dict(result)\n",
    "\n",
    "message = result.model_dump()\n",
    "\n",
    "pprint(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8e1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"Why do parrots have colorful feathers?\")\n",
    "reasoning_steps = [b for b in response.content_blocks if b[\"type\"] == \"reasoning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dabe681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 1048,\n",
       "   'prompt_tokens': 14,\n",
       "   'total_tokens': 1062,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 1048,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_provider': 'openai',\n",
       "  'model_name': 'gpt-5-nano-2025-08-07',\n",
       "  'system_fingerprint': None,\n",
       "  'id': 'chatcmpl-CmK4e8eADr6pJFzylDyPn19SnuLk5',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'length',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--019b17ec-a79b-7bc0-802f-d96a666a2740-0',\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 14,\n",
       "  'output_tokens': 1048,\n",
       "  'total_tokens': 1062,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 1048}}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: get_weather\n",
      "Args: {'location': 'Boston'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    return f\"It's sunny in {location}.\"\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "response = model_with_tools.invoke(\"What's the weather like in Boston?\")\n",
    "for tool_call in response.tool_calls:\n",
    "    # View tool calls made by the model\n",
    "    print(f\"Tool: {tool_call['name']}\")\n",
    "    print(f\"Args: {tool_call['args']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f503577",
   "metadata": {},
   "source": [
    "# Experiments with agent\n",
    "\n",
    "## output schema\n",
    "content,\n",
    "reasoning tokens,\n",
    "tool calls,\n",
    "tool fails\n",
    "source url\n",
    "source inline\n",
    "usage data\n",
    "\n",
    "```python\n",
    "class UIMessageChunk:\n",
    "  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca3a190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"\"\"\n",
    "            Question 1: What is the weather in New York? \n",
    "            Question 2: Use reasoning to answer this. Give me the smallest positive integer that has exactly 10 divisors.\n",
    "            Show every deduction you make and justify why your answer is the smallest.\"\"\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3c77300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\n            Question 1: What is the weather in New York? \\n            Question 2: Use reasoning to answer this. Give me the smallest positive integer that has exactly 10 divisors.\\n            Show every deduction you make and justify why your answer is the smallest.', additional_kwargs={}, response_metadata={}, id='d9735949-e088-4238-aecd-5b7d01b39e5b'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 792, 'prompt_tokens': 232, 'total_tokens': 1024, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 768, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CmjR6wTd8ytvRr8W2aTIUevQwoRtO', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b1dbc-3edd-7f11-b1a1-fa559d7c9c96-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'New York'}, 'id': 'call_hwCWxUNGnJU6PazzrBFL72hV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 232, 'output_tokens': 792, 'total_tokens': 1024, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 768}}),\n",
       " ToolMessage(content='The weather in New York is sunny and 25°C', name='get_weather', id='c9fed42f-0031-44b6-888a-0eb457945f62', tool_call_id='call_hwCWxUNGnJU6PazzrBFL72hV'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1048, 'prompt_tokens': 272, 'total_tokens': 1320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1048, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CmjRDP7iF0NEa72whHYggKkFdRtOh', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None}, id='lc_run--019b1dbc-5bbf-7711-befa-56515fe33901-0', usage_metadata={'input_tokens': 272, 'output_tokens': 1048, 'total_tokens': 1320, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1048}})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_response.get(\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a972c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 629, 'prompt_tokens': 208, 'total_tokens': 837, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CmjSkNg7Tcg8Y0RrUz2OHBvMq28LH', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b1dbd-d08f-7f51-bdb8-ed1e1213c151-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'New York'}, 'id': 'call_TTQ2v2DJTYUJCP7aDZ6xaWnk', 'type': 'tool_call'}, {'name': 'calculate', 'args': {'expression': '0'}, 'id': 'call_jQmeY8KzRsDZcp9fBwuBus7W', 'type': 'tool_call'}], usage_metadata={'input_tokens': 208, 'output_tokens': 629, 'total_tokens': 837, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Result: 0', name='calculate', id='151b4194-40fc-49e4-9ab8-373c42ea8115', tool_call_id='call_jQmeY8KzRsDZcp9fBwuBus7W')]}}\n",
      "{'tools': {'messages': [ToolMessage(content='The weather in New York is sunny and 25°C', name='get_weather', id='6aab7ea9-5a00-4339-b9b5-aed472f5647e', tool_call_id='call_TTQ2v2DJTYUJCP7aDZ6xaWnk')]}}\n",
      "{'model': {'messages': [AIMessage(content='- Weather in New York: sunny and 25°C.\\n- The earliest arriver: Ngọc.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 541, 'prompt_tokens': 291, 'total_tokens': 832, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CmjSqKnY0vJ7fntH3LCaXg0LNNceP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b1dbd-e967-7032-ab81-b9e2420d6f84-0', usage_metadata={'input_tokens': 291, 'output_tokens': 541, 'total_tokens': 832, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}})]}}\n"
     ]
    }
   ],
   "source": [
    "agent_response_stream = agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"What is the weather in New York?, Sơn đến sớm hơn Hương, nhưng muộn hơn Ngọc. Ai là người đến sớm nhất?\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "for chunk in agent_response_stream:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee26a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"CHUNK: ==> {'model': {'messages': [AIMessage(content='', \"\n",
      " \"additional_kwargs={'refusal': None}, response_metadata={'token_usage': \"\n",
      " \"{'completion_tokens': 46, 'prompt_tokens': 108, 'total_tokens': 154, \"\n",
      " \"'completion_tokens_details': {'accepted_prediction_tokens': 0, \"\n",
      " \"'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, \"\n",
      " \"'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, \"\n",
      " \"'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', \"\n",
      " \"'system_fingerprint': 'fp_7f8eb7d1f9', 'id': \"\n",
      " \"'chatcmpl-CoUpkiqCwgLkPtJvoOjENeOzJ5J4B', 'service_tier': 'default', \"\n",
      " \"'finish_reason': 'tool_calls', 'logprobs': None}, \"\n",
      " \"id='lc_run--019b36cc-f270-7dc0-9190-39e76fd9f3c2-0', tool_calls=[{'name': \"\n",
      " \"'get_weather', 'args': {'location': 'New York'}, 'id': \"\n",
      " \"'call_Ca1Nvra1wUgaoTLEAsSZ49Pr', 'type': 'tool_call'}, {'name': 'calculate', \"\n",
      " \"'args': {'expression': '3^3'}, 'id': 'call_c92cdvUWRBeTISmMYvcNQ3Tb', \"\n",
      " \"'type': 'tool_call'}], usage_metadata={'input_tokens': 108, 'output_tokens': \"\n",
      " \"46, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': \"\n",
      " \"0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\")\n",
      "========================================================\n",
      "step: model\n",
      "(\"content_blocks: [{'type': 'tool_call', 'name': 'get_weather', 'args': \"\n",
      " \"{'location': 'New York'}, 'id': 'call_Ca1Nvra1wUgaoTLEAsSZ49Pr'}, {'type': \"\n",
      " \"'tool_call', 'name': 'calculate', 'args': {'expression': '3^3'}, 'id': \"\n",
      " \"'call_c92cdvUWRBeTISmMYvcNQ3Tb'}]\")\n",
      "content: {'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 108, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7f8eb7d1f9', 'id': 'chatcmpl-CoUpkiqCwgLkPtJvoOjENeOzJ5J4B', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b36cc-f270-7dc0-9190-39e76fd9f3c2-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'New York'}, 'id': 'call_Ca1Nvra1wUgaoTLEAsSZ49Pr', 'type': 'tool_call'}, {'name': 'calculate', 'args': {'expression': '3^3'}, 'id': 'call_c92cdvUWRBeTISmMYvcNQ3Tb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 108, 'output_tokens': 46, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "\n",
      "\n",
      "\n",
      "(\"CHUNK: ==> {'tools': {'messages': [ToolMessage(content='Result: 0', \"\n",
      " \"name='calculate', id='10078e45-bc5c-4ea7-8408-3d66a4e2ece5', \"\n",
      " \"tool_call_id='call_c92cdvUWRBeTISmMYvcNQ3Tb')]}}\")\n",
      "========================================================\n",
      "step: tools\n",
      "\"content_blocks: [{'type': 'text', 'text': 'Result: 0'}]\"\n",
      "content: {'tools': {'messages': [ToolMessage(content='Result: 0', name='calculate', id='10078e45-bc5c-4ea7-8408-3d66a4e2ece5', tool_call_id='call_c92cdvUWRBeTISmMYvcNQ3Tb')]}}\n",
      "\n",
      "\n",
      "\n",
      "(\"CHUNK: ==> {'tools': {'messages': [ToolMessage(content='The weather in New \"\n",
      " \"York is sunny and 25°C', name='get_weather', \"\n",
      " \"id='9e93e789-27a6-4f22-8d95-25cfa7877543', \"\n",
      " \"tool_call_id='call_Ca1Nvra1wUgaoTLEAsSZ49Pr')]}}\")\n",
      "========================================================\n",
      "step: tools\n",
      "(\"content_blocks: [{'type': 'text', 'text': 'The weather in New York is sunny \"\n",
      " \"and 25°C'}]\")\n",
      "content: {'tools': {'messages': [ToolMessage(content='The weather in New York is sunny and 25°C', name='get_weather', id='9e93e789-27a6-4f22-8d95-25cfa7877543', tool_call_id='call_Ca1Nvra1wUgaoTLEAsSZ49Pr')]}}\n",
      "\n",
      "\n",
      "\n",
      "(\"CHUNK: ==> {'model': {'messages': [AIMessage(content='The weather in New \"\n",
      " \"York is sunny and 25°C. The result of 3^3 is 27.', \"\n",
      " \"additional_kwargs={'refusal': None}, response_metadata={'token_usage': \"\n",
      " \"{'completion_tokens': 24, 'prompt_tokens': 187, 'total_tokens': 211, \"\n",
      " \"'completion_tokens_details': {'accepted_prediction_tokens': 0, \"\n",
      " \"'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, \"\n",
      " \"'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, \"\n",
      " \"'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', \"\n",
      " \"'system_fingerprint': 'fp_7f8eb7d1f9', 'id': \"\n",
      " \"'chatcmpl-CoUplvsC2ctW71IGG3efwyGVMjv4s', 'service_tier': 'default', \"\n",
      " \"'finish_reason': 'stop', 'logprobs': None}, \"\n",
      " \"id='lc_run--019b36cc-f9a2-7422-b860-5bb0996ab83f-0', \"\n",
      " \"usage_metadata={'input_tokens': 187, 'output_tokens': 24, 'total_tokens': \"\n",
      " \"211, 'input_token_details': {'audio': 0, 'cache_read': 0}, \"\n",
      " \"'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\")\n",
      "========================================================\n",
      "step: model\n",
      "(\"content_blocks: [{'type': 'text', 'text': 'The weather in New York is sunny \"\n",
      " \"and 25°C. The result of 3^3 is 27.'}]\")\n",
      "content: {'model': {'messages': [AIMessage(content='The weather in New York is sunny and 25°C. The result of 3^3 is 27.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 187, 'total_tokens': 211, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7f8eb7d1f9', 'id': 'chatcmpl-CoUplvsC2ctW71IGG3efwyGVMjv4s', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b36cc-f9a2-7422-b860-5bb0996ab83f-0', usage_metadata={'input_tokens': 187, 'output_tokens': 24, 'total_tokens': 211, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"What is the weather in New York?, What is 3^3?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    pprint(f\"CHUNK: ==> {chunk}\")\n",
    "    for step, data in chunk.items():\n",
    "        print(\"========================================================\")\n",
    "        print(f\"step: {step}\")\n",
    "        pprint(f\"content_blocks: {data['messages'][-1].content_blocks}\")\n",
    "        print(f\"content: {chunk}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40d5483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': 'call_4usR76tHxDfQ441xzR4seB07', 'name': 'get_weather', 'args': '', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '{\"', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'city', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\":\"', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'San', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': ' Francisco', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\"}', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: tools\n",
      "content: [{'type': 'text', 'text': \"It's always sunny in San Francisco!\"}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'According'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' to'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' weather'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' tool'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \" It's\"}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' always'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' sunny'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' San'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Francisco'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '!\\n\\n'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Would'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' you'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' like'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' current'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' temperature'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' forecast'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' details'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'humidity'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' wind'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' highs'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '/l'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ows'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ')'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' today'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '?'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "async for token, metadata in agent.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"node: {metadata['langgraph_node']}\")\n",
    "    print(f\"content: {token.content_blocks}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Search for AI news and summarize the findings\n",
      "Agent: I don’t have live web access, so I can’t run a real-time search of AI news. I can still help in a few ways:\n",
      "\n",
      "- Provide a concise, up-to-date-style briefing based on my latest training (through mid-2024) that highlights major themes and takeaways.\n",
      "- Help you set up a process to get current AI news (suggest sources, RSS, or a simple script to fetch headlines from a news API) and then summarize whatever headlines you provide.\n",
      "- If you paste specific headlines or links, I’ll read them and give you a structured summary and context.\n",
      "\n",
      "Here’s a high-level summary of major AI news themes observed up to mid-2024 (without specific dates):\n",
      "- Regulation and safety: Increased focus on AI risk management, transparency, accountability, and governance frameworks across regions (e.g., debates around AI Act-style rules, safety standards, and compliance requirements).\n",
      "- Model development and safety: Ongoing advances in large language models and multimodal systems, with emphasis on safety controls, alignment challenges, and safer deployment practices.\n",
      "- Open-source and openness: Growing activity around open-source LLMs and community-led governance discussions, balanced with concerns about misuse and responsible use.\n",
      "- Enterprise adoption: Widespread integration of AI into workflows, data analytics, automation, and customer-facing products, accompanied by data privacy and governance considerations.\n",
      "- AI hardware and efficiency: Continued demand for specialized accelerators and optimized inference hardware to reduce latency and cost, along with energy considerations.\n",
      "- AI-generated content and provenance: Issues around copyright, licensing, watermarking, detection of synthetic media, and user attribution.\n",
      "- Sector applications: AI’s impact in healthcare, finance, education, and other industries, with both innovative use cases and regulatory/compliance considerations.\n",
      "- Competitive landscape: Ongoing competition among major players (and emerging players) around capabilities, safety measures, and business models.\n",
      "- Ethical and societal impact: Debates on bias, misinformation, job displacement, and equitable access to AI benefits.\n",
      "\n",
      "If you’d like, I can:\n",
      "- Create a tailored brief: tell me your region, industries of interest, and how deep you want the summary (bullet points vs. short analysis).\n",
      "- Build a current-news workflow: I can outline a simple setup (sources, frequency, format) and a template you can use to generate weekly AI-news summaries.\n",
      "- Analyze specific headlines: paste a list of headlines or links, and I’ll summarize the findings and add context or potential implications.\n",
      "\n",
      "How would you like to proceed? If you want a current snapshot, tell me your preferred sources or allow me to work from a set of sources you specify, and I’ll synthesize them into a briefing.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1cb66ad",
   "metadata": {},
   "source": [
    "## Clean the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b75b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22d38bf7",
   "metadata": {},
   "source": [
    "- AIMessage\n",
    "- AIMessageChunk (stream)\n",
    "  - Source\n",
    "  - Suggestion\n",
    "- ToolMessage\n",
    "\n",
    "- UserMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1fac4",
   "metadata": {},
   "source": [
    "# Experiments with multi-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755bc97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
