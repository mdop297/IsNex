{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96119035",
   "metadata": {},
   "source": [
    "# Target\n",
    "- create agent => OKAY\n",
    "- get text content response => OKAY\n",
    "- get tools call response => OKAY\n",
    "- get structure ouput => OKAY\n",
    "- get data sources \n",
    "  - url\n",
    "  - document\n",
    "- get usage data\n",
    "- can retrieve data from vector db\n",
    "- add memory to agent\n",
    "  - short term\n",
    "  - long term\n",
    "- add agent guardrail\n",
    "- use mcp\n",
    "- use middleware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31384c2f",
   "metadata": {},
   "source": [
    "## Create basic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7044839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(\n",
    "#     model=\"gpt-4.1-nano\",\n",
    "#     temperature=0.1,\n",
    "#     max_tokens=1000,\n",
    "#     timeout=30\n",
    "# )\n",
    "model = init_chat_model(\"gpt-4.1-nano\", temperature=0.1, max_tokens=1000, timeout=15)\n",
    "\n",
    "agent = create_agent(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9135762",
   "metadata": {},
   "source": [
    "### Agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36b21510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_tool_call\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get weather information for a location.\"\"\"\n",
    "    return f\"Weather in {location}: Sunny, 72째F\"\n",
    "\n",
    "\n",
    "@wrap_tool_call\n",
    "def handle_tool_errors(request, handler):\n",
    "    \"\"\"Handle tool execution errors with custom messages.\"\"\"\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        # Return a custom error message to the model\n",
    "        return ToolMessage(\n",
    "            content=f\"Tool error: Please check your input and try again. ({str(e)})\",\n",
    "            tool_call_id=request.tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "tools = [search, get_weather]\n",
    "\n",
    "agent_with_tools = create_agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    tools=[search, get_weather],\n",
    "    middleware=[handle_tool_errors],\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7e8db",
   "metadata": {},
   "source": [
    "### agent with structure output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db8528a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str | None = None\n",
    "    email: str | None = None\n",
    "    phone: str | None = None\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[search],\n",
    "    response_format=ToolStrategy(ContactInfo),\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate. Extract contact info ONLY if present. If missing contact info, return empty string.\"\n",
    ")\n",
    "\n",
    "# BUG: There is a big problem here if the contact info is not present\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"},\n",
    "                #  {\"role\": \"user\", \"content\": \"what is machine learning?\"}\n",
    "                 ]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "113b23a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.structured_output import ProviderStrategy\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    response_format=ProviderStrategy(ContactInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"},\n",
    "        {\"role\": \"user\", \"content\": \"what is machine learning?\"}\n",
    "                 ]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8782c",
   "metadata": {},
   "source": [
    "### Agent memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0b5f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I prefer technical explanations', additional_kwargs={}, response_metadata={}, id='66d622c2-b00e-4410-85c0-c53be1945d30'),\n",
       "  AIMessage(content=\"Understood. Please specify the topic or subject you'd like a technical explanation for.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 65, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7f8eb7d1f9', 'id': 'chatcmpl-CmMza8YKw5e6bwZTLJ1l8Z1fo36Lx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b1897-d3ed-7633-8f0b-54d6144b4c9d-0', usage_metadata={'input_tokens': 65, 'output_tokens': 17, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'user_preferences': {'style': 'technical', 'verbosity': 'detailed'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.agents import AgentState\n",
    "\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[search, get_weather],\n",
    "    state_schema=CustomState\n",
    ")\n",
    "# The agent can now track additional state beyond messages\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde77896",
   "metadata": {},
   "source": [
    "### Streaming response (text content, tool calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d94b9b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Search for AI news and summarize the findings. After that tell me the weather in San Francisco and New York.\n",
      "Calling tools: ['search', 'get_weather', 'get_weather']\n",
      "Agent: Weather in New York: Sunny, 72째F\n",
      "Agent: Here's a summary of the AI news: (Note: As I cannot fetch specific news articles directly, please specify if you'd like a summary of recent AI developments or headlines you are interested in.)\n",
      "\n",
      "The weather in San Francisco is sunny with a temperature of 72째F, and the weather in New York is also sunny with a temperature of 72째F.\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_with_tools.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings. After that tell me the weather in San Francisco and New York.\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    # Each chunk contains the full state at that point\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent: {latest_message.content}\")\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11d401",
   "metadata": {},
   "source": [
    "### Get source content "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
